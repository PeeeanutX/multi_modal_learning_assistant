AI-Based Business Information Systems
AI-Enabled Engagement
Prof. Dr. Ulrich Gnewuch
Lecture
AI-Enabled Business Capabilities
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 2Course Organization
Exercise
Exercise 1: 
Robotic Process 
Automation Case StudyExercise 2: 
Human -Centered 
Chatbot DesignExercise 3: 
Explainable AI 
Techniques
Foundations Introduction to AI in Business 
& Information SystemsDesign & Management of AI-
Based Information SystemsAI-Enabled EngagementAI-Enabled Insights & DecisionsAI-Enabled Innovation
Industry Talk 
ZF GroupExercise 4: 
Generative AI & 
Innovation
AI-Enabled Automation AI Technologies & Trends
Conversational AIExplainable AIGenerative AIAI Ethics & Responsible AIRECAP FROM LAST LECTURE:
•What are examples of software
robots?
•Please organize the task types in the 
Theory of AI Job Replacement 
based on the order in which AI is 
expected to perform them.
•What are key challenges and risks of 
AI-enabled automation?
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 4Learning Goals
•Explain the concept of user 
engagement and its three dimensions 
•Describe how AI can enable user 
engagement through human -like 
interactions
•Explain the relationship between social 
cues and social responses
•Discuss the benefits and risks of AI -
enabled engagement and human -like AIProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 5What does “Engagement” mean?
https://www.dictionary.com/browse/engage•Engagement with …
–a company and           
its products
–an employer
–a technology
–… 
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 6Types of Engagement
Customer
Engagement
Employee
Engagement
User
Engagement•Higher levels of customer engagement increase customer 
loyalty and purchase frequency, resulting in better overall 
business performance
•Engaged customers are more likely to share positive 
experiences and recommend products or services to 
others
•Fostering customer engagement is in the best interest of a 
company and should be actively encouraged
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 7Customer Engagement 
Customer engagement is the intensity of an individual’s participation 
in and connection with a company’s offerings and/or activities.
Vivek et al. 2012•The outcomes of high employee engagement are 
improved productivity, loyalty, job satisfaction, and 
organizational performance
•A positive workplace culture, recognition, and opportunities 
for autonomy and growth foster employee engagement
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 8Employee Engagement
Employee engagement refers to employees’ willingness to fully 
invest themselves physically, cognitively, and emotionally into 
their work roles.
Kahn 1990
9User Engagement
User engagement is defined as a user’s technology -related state 
of mind characterized by specific cognitive, emotional, and 
behavioral manifestations during interactions with technology.
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems•User engagement is positively related to user satisfaction, loyalty, and usage frequency
•Engaged users are more likely to contribute to user -generated content and to demonstrate a 
strong emotional connection to the technology
•User engagement has three subdimensions: cognitive, emotional, and behavioral engagement
•Our focus is on user engagement
Lehrer et al. 2023Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 10Dimensions of User Engagement
Cognitive
EngagementEmotional
EngagementBehavioral
Engagement
Users’ positively or negatively 
valenced thoughts, concentration, 
and reflections during an 
interaction with a technology 
feature, such as:
•Attention
•Absorption
•…Users’ affective reactions during 
an interaction with a technology 
feature, includes positive and 
negative feelings such as:
•Enjoyment
•Love
•Frustration
•Anxiety
•…Users’ behavioral interactions 
with a technology feature, 
such as:
-Content creation
-Content consumption
-Responses 
-Interactions (e.g., clicks)
-…
Lehrer et al. 2023Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 11Behavioral Engagement: Example
Social MediaProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 12Cognitive Engagement: Example
https://www.theguardian.com/global/2021/aug/22/how -digital -media -turned -us-
all-into-dopamine -addicts -and-what -we-can-do-to-break -the-cyclehttps://www.fastcompany.com/40491939/netflix -ceo-reed-
hastings -sleep -is-our-competitionProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 13Affective Engagement: Example
https://replika.com/https://www.youtube.com/watch?v=DTq0MaOwTjE
How can AI enable user 
engagement?
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 1415AI-Enabled Engagement
AI-enabled engagement refers to the use of AI to create 
interactions that resemble those with a human.
Benbya et al. 2021; Lankton et al. 2015
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems•Users consider technologies with 
a human -like interface to be more 
engaging than other interfaces 
that perform the same functions
•AI can be used to provide highly 
human -like experiences
What characterizes interactions 
between humans? What makes 
an experience “human -like”?
•In human -human interaction, a person 
perceives, interprets, and responds to a 
wide array of social cues:
–Facial expressions (e.g., smiling)
–Gestures (e.g., head nodding)
–German forms of address (e.g., Du vs. Sie)
–…
•Social cues help to clarify people’s 
meanings and intentions
•Social cues influence various social 
processes (e.g., communication)
Chair of Explainable AI -based Business Information Systems 17Social Cues in Human -Human Interaction
GestureBody posture
Body posture
Interpersonal distanceGaze
Vocal behaviorHead position
Burgoon et al. 2010
Prof. Dr.Ulrich Gnewuch•Users respond in a similar way to social cues from technology:
18Social Cues in Human -AI Interaction
Chair of Explainable AI -based Business Information Systems Prof. Dr.Ulrich GnewuchCues Examples
Physical Face, eyes, body, movement
LanguageInteractive language use, spoken 
language, language recognition
PsychologicalPreferences, humor, personality, 
feelings, empathy, “I’m sorry”
Social 
DynamicsTurn taking, cooperation, praise for 
good work, answering questions, 
reciprocity
Social RolesDoctor, teammate, opponent, teacher, 
pet, guide
Fogg 2002
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 19Example: Physical Cues
Realistic 3D avatars with human faces and body movements Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 20Example: Language Cues
→Conversational 
AI Lecture 
Chatbots and voice assistants that 
converse with us via natural languageProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 21Example: Social Role Cues
https://www.theverge.com/2024/6/5/24170480/as
ana-ai-teammate -workflow -assistant -chatbot
https://www.zdnet.com/article/can -ai-curb-loneliness -in-older -
adults -this-robot -companion -is-proving -its-possible/AI designed to take on specific roles such 
as teammates, companions, doctors, etc.Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 22Digital Humans –The Future of AI -Enabled Engagement?
https://www.youtube.com/watch?v=S3F1vZYpH8c
Social Responses :
How do social cues lead to human -
like interactions with AI?
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 24Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 25Social Response Theory (Computers are Social Actors Paradigm)
Clifford Nass
Nass et al. 1994; Nass & Moon 2000
Youngme MoonProf. Dr.Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 26Social Response Theory
A technology possesses 
characteristics normally 
associated with humansApplication of various scripts, 
labels, and expectations in 
accordance with prior experiencesEmotional, cognitive, or behavioral 
reactions similar to reactions shown 
during interactions with humans result in triggerSocial Cues Mindless Behavior Social Responses
Nass et al. 1994, Nass & Moon 2000Prof. Dr.Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 27Example #1
Social Cues Mindless Behavior Social Responses
Name tag of 
a chatbot 
(“Emma” vs. 
“ChatBotX ”)People have names 
→chatbot appears 
like a real person Chatbot “Emma” is more 
likeable, sociable, and 
friendly than “ ChatBotX ”
Araujo 2018Prof. Dr.Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 28Example #2
Social Cues Mindless Behavior Social Responses
Male vs. female 
voice output of a 
computerGender stereotypes:
•Male -voiced computer = more 
informative about computers 
•Female -voiced computer = 
more informative about love 
and relationshipsGender attribution 
to computer
Nass et al. 1997Prof. Dr.Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 291997?
Nass, C., Moon, Y., & Green, N. ( 1997 ). Are machines gender neutral? Gender -stereotypic responses to 
computers with voices. Journal of Applied Social Psychology , 27(10), 864 –876.Prof. Dr.Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 30Gender Stereotypes Today
UNESCO ( https://unesdoc.unesco.org/ark:/48223/pf0000367416.locale=en ), 
https://www.technologyreview.com/2019/05/22/65758/female -voice -assistants -fuel-damaging -gender -stereotypes -says-un-study
“Most AI voice assistants are gendered as young women, and are mostly 
used to answer questions or carry out tasks like checking the weather, 
playing music, or setting reminders. This sends a signal that women are 
docile, eager -to-please helpers without any agency, always on hand to help 
their masters, helping to reinforce harmful stereotypes.”Challenges of AI -Enabled 
Engagement and Human -Like AI
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 31Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 32Uncanny Valley 
“I have noticed that, in climbing 
toward the goal of making robots 
appear human, our affinity for them 
increases until we come to a valley, 
which I call the uncanny valley .”
Mori 1970
Example: A robot that looks almost human 
but certain features are not quite right•Mori (1970) proposed a nonlinear 
relation between a character’s 
degree of human -likeness and the 
human perceiver’s emotional 
response
•The dip in emotional response 
just before total human -likeness 
is referred to as the uncanny valley
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 33Uncanny Valley Theory
Mori 1970; Mone 2016
Comfort level / emotional response•Small deviations from humanness can 
make a big difference
•This not only includes visual cues or 
physical appearance but also to language 
(e.g., computer generated voices)
•Business should stay out of the uncanny 
valley
•Researchers can explore and push the 
boundaries of human likeness
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 34Uncanny Valley: Scoping for the Right Goal 
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 35Ethical Questions
How human should a 
non-human robot be?Should AI use social 
cues to look and act 
like a human?
What happens when 
we cross the uncanny 
valley?Should people know 
that they are 
interacting with AI 
instead of a human?
Will artificial human -
likeness endanger our 
“real” humanness long 
term?“In 1950, Alan Turing proposed an “imitation game” as the ultimate test of 
whether a machine was intelligent: could a machine imitate a human so well 
that its answers to questions are indistinguishable from those of a human. 
Ever since, creating intelligence that matches human intelligence has 
implicitly or explicitly been the goal of thousands of researchers, engineers 
and entrepreneurs. The benefits of human -like artificial intelligence 
include soaring productivity, increased leisure, and perhaps most 
profoundly, a better understanding of our own minds.”
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 36Benefits of Human -Like AI
https://digitaleconomy.stanford.edu/news/the -turing -trap-the-promise -peril-of-human -like-artificial -intelligence/“Fundamentally, whatever human -likeness we create 
on machines is not genuine humanness because it 
lacks the physical characteristics of our body and the 
self-awareness that only occur in our biology.”
Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 37Risks of Human -Like AI
Porra et al. 2020Your View on Human -Like AI
Should AI be designed to resemble and 
behave like humans? Why or why not? Should 
there be any limitations or ethical boundaries, 
and if so, what are the reasons for them? What 
do you think are the long -term consequences 
for humanity?
→Discuss these questions with a partner for 
~5 minutes and be ready to share your 
opinionsProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 39Key Takeaways From This Lecture
•Engagement describes the depth of interaction and 
connection users have with a technology
•Technologies with a human -like interface are more 
engaging than other interfaces that perform the same 
functions
•AI can be used to provide highly human -like experiences 
through social cues: physical appearance, natural 
language, social roles, …
•Social cues automatically trigger social responses from 
humans and thereby influence human behavior
•“Almost -human” AI can easily fall into the uncanny valley
•There is an ongoing debate about whether or not AI 
should be designed to resemble and behave like humansProf. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 40Thank you for 
your attention!
Any questions?Prof. Dr. Ulrich Gnewuch Chair of Explainable AI -based Business Information Systems 41References
Araujo, T. (2018). Living up to the chatbot hype: The influence of anthropomorphic design cues and communicative agency frami ng on conversational agent and 
company perceptions. Computers in Human Behavior, 85, 183 –189.
Benbya , H., Pachidi , S., & Jarvenpaa , S. L. (2021). Special Issue Editorial : Artificial Intelligence in Organizations : Implications for Information Systems Research. 
Journal of the Association for Information Systems, 22, 281 –303. 
Burgoon JK, Guerrero L, Floyd K (2010) Nonverbal communication. Routledge, New York, NY, USA
Fogg, B. J. (2002). Computers as Persuasive Social Actors. In Persuasive Technology: Using Computers to Change What We Think andDo (pp. 89 –120). 
Morgan Kaufmann Publishers.
Kahn, W. A. (1990). Psychological conditions of personal engagement and disengagement at work. Academy of management journal, 33(4), 692 -724.
Lankton, N. K., McKnight, D. H., & Tripp, J. (2015). Technology, humanness, and trust: Rethinking trust in technology. Journa l of the Association for Information 
Systems, 16(10), 1.
Lehrer, C., Constantiou , I., Matt, C., & Hess, T. (2023). How Ephemerality Features Affect User Engagement with Social Media Platforms. MIS Quarterl y, 47(4).
Mone, G. (2016). The edge of the uncanny. Communications of the ACM, 59(9), 17 –19. 
Mori, M. (1970). The uncanny valley. Energy, 7(4), 33 –35.
Nass, C., Steuer , J., & Tauber, E. R. (1994). Computers are social actors. In Proceedings of the SIGCHI conference on Human factors in comput ingsystems (pp. 
72-78).
Nass, C., Moon, Y., & Green, N. (1997). Are machines gender neutral? Gender -stereotypic responses to computers with voices. Jour nal of Applied Social 
Psychology, 27(10), 864 –876.
Nass, C., & Moon, Y. (2000). Machines and mindlessness: Social responses to computers. Journal of Social Issues, 56(1), 81 –103. 
Porra, J., Lacity , M., & Parks, M. S. (2020). “Can Computer Based Human -Likeness Endanger Humanness?” –A Philosophical and Ethical Perspective o n Digital 
Assistants Expressing Feelings They Can’t Have”. Information Systems Frontiers, 22(3), 533 –547. 
Vivek, S. D., Beatty, S. E., & Morgan, R. M. (2012). Customer engagement: Exploring customer relationships beyond purchase. J ournal of marketing theory and 
practice, 20(2), 122 -146.